cv_score,
time_spent))
}
gbm.US_h3d3_roll_mini = gbm.roc_roll(forecast = 3, lags = 3, zoo.US_lag0, run.full = FALSE, country = "US", runs = 10)
gbm.US_h3d3_roll_mini
gbm.roc_roll <- function(forecast = 0, lags = 3, zoo.C_lag0,  country, distr = "bernoulli", train = 1.0, run.full = TRUE, runs = 10,  m = 400, wind = 317, steps = 0.01, end_train = "1985-08-01")
{
h = forecast
d = lags
c = country
if(d == 0)
{
horizon = h + 1
}
else
{
horizon = seq(from =h+1, to = h+d)
}
#Lag h+1,h+2,...,h+d
zoo.C_lagRESULT = (na.omit(merge(lag(zoo.C_lag0[,2:ncol(zoo.C_lag0)], k = -horizon))))
#Need to get Recession Information because not included in Lags
REC_lagRESULT = window(zoo.C_lag0[,1], start = start(zoo.C_lagRESULT), end = end(zoo.C_lagRESULT))
train_start = start(zoo.C_lagRESULT)
train_end = end_train
test_start = as.Date(train_end) + months(h+1)
test_end = end(zoo.C_lagRESULT)
#Moving Window Size
#window = wind
#Setting Number of run (Not to be confused with M trees)
if(run.full == TRUE){
#run = (nrow(zoo.C_lagRESULT)-window-h - 1)
run = elapsed_months(test_end, test_start)
}
else{
run = runs
}
#Create prediction vector
pred_final = vector("numeric")
#cv_score = vector("integer")
#Create store for average and frequency count of variables selected
df.store = data.frame()
#Create positive prediction
pos_var = vector("integer")
pos_uniq = vector("integer")
#Time
ptm <- proc.time()
#Big for loop that will iterate about 400 times and predict out of sample and increment by 1
for(i in 1:run)
{
#Get zoo from 1 to 180, then 2 to 182, then 3 to 183 all the way to run + window so like 10 to 190
#shift  <- sum(i,window)
start_shift  <- months(i-1) + as.Date(train_start)
end_shift <- months(i-1) + as.Date(train_end)
zoo.C_shift =  window(zoo.C_lagRESULT, start = start_shift, end = end_shift)
REC_shift = window(REC_lagRESULT, start = start_shift, end = end_shift)
zoo.C_predict = window(zoo.C_lagRESULT, start = (as.Date(test_start)+months(i-1)), end = (as.Date(test_start)+months(i-1)))
#     gbm.C = gbm(REC_shift ~ . ,
#                 data = zoo.C_shift,
#                 distribution = distr,
#                 shrinkage = steps,
#                 bag.fraction = 1,
#                 cv.folds = 5,
#                 train.fraction = 1.0,
#                 n.trees = m)
#     gbm.C = gbm.fit(x = zoo.C_shift,
#                 y = REC_shift,
#                 distribution = distr,
#                 shrinkage = steps,
#                 bag.fraction = 1,
#                 n.trees = m,
#                 verbose = FALSE)
#
#Get the summary of GBM model
#     sum_gbm.C = summary(gbm.C, plotit= FALSE)
#Print best iteration and store
#best.iter_cv = gbm.perf(gbm.C, method="cv")
#cv_score[i] = best.iter_cv
cv_score = m
#Forecast using LAST time to forecast NEXT h period
#next_predict = sum(shift,h,1)
#     pred_final[i] =  predict(gbm.C,
#                             zoo.C_predict,
#                             n.trees= m,
#                             type="response")
pred_final[i] = 0
#Store number of positive variables
#     pos_var[i] = sum(as.numeric(sum_gbm.C[2] >0))
#Update average and frequency
#     if(length(df.store) == 0)
#     {
#       df.store = data.frame(NAME = sum_gbm.C[order(sum_gbm.C[[1]]),1], AVG = 0, FREQ = 0)
#       rownames(df.store) = df.store$NAME
#     }
#     if(length(df.store) > 0)
#     {
#       order_var = order(sum_gbm.C[[1]])
#       #Add I_j^2 value
#       df.store[,2] <- df.store[,2] + sum_gbm.C[order_var,2]
#       #Add to get frequency of each I_j^2
#       df.store[,3] <- df.store[,3] + as.numeric(sum_gbm.C[order_var,2]>0)
#     }
#
#
#
#     if(i %% 10 == 0)
#     {
#       cat(i)
#       save(pred_final, file = "~/Google Drive/Independent Work/Saved RData/save_pred_recent_gbm_roll.RData")
#       #save(pred_final, file = paste("gbm_",c,"_h",h,"d",d,"_pred_",run,"_.RData",sep=""))
#     }
}
#   #Print how long it took for ALL the run
#   time_spent = proc.time() - ptm
#
#   #Take average of I_j^2 value
#   df.store[,2] = df.store[,2]/run
#   df.store[,3] = df.store[,3]/run
#
#   #Return the average score from highest to lowest
#   df.store = df.store[order(df.store[,2], decreasing = TRUE),]
#
#   #Convert into time series object
ts.pred = ts(pred_final, start = c(year(test_start),month(test_start),day(test_start)), frequency = 12)
#ts.pos = ts(pos_var, start = c(year(test_start),month(test_start),day(test_start)), frequency = 12)
ts.REC = ts(REC_lagRESULT, start = c(year(test_start),month(test_start)), end = c(end(ts.pred)[1],end(ts.pred)[2]), frequency = 12)
#Plot Prediction Against ACTUAL Recession
plot(ts.REC, col = "blue", ylab = "Prob. of Recession", axes = FALSE)
par(new=TRUE)
plot(ts.pred, col = "red", ylab = "Prob. of Recession",
main = paste(c, ":", m, "Boosting Roll Forecast",h,"Months"),
axes = TRUE,
ylim=c(0,1))
#setwd("~/Google Drive/Independent Work/Writing/Graphs")
#dev.copy(png, paste(c,"_boost_","h",h,"d",d,"_outsample_",run,"_.png", sep = ""))
#dev.off()
#Return Prediction, Final Score, CV,Score and Ideally ROC
return(list(ts.REC,
ts.pred,
roc(ts.REC,ts.pred),
#df.store,
#ts.pos,
cv_score,
#time_spent
))
}
gbm.US_h3d3_roll_mini = gbm.roc_roll(forecast = 3, lags = 3, zoo.US_lag0, run.full = FALSE, country = "US", runs = 10)
gbm.roc_roll <- function(forecast = 0, lags = 3, zoo.C_lag0,  country, distr = "bernoulli", train = 1.0, run.full = TRUE, runs = 10,  m = 400, wind = 317, steps = 0.01, end_train = "1985-08-01")
{
h = forecast
d = lags
c = country
if(d == 0)
{
horizon = h + 1
}
else
{
horizon = seq(from =h+1, to = h+d)
}
#Lag h+1,h+2,...,h+d
zoo.C_lagRESULT = (na.omit(merge(lag(zoo.C_lag0[,2:ncol(zoo.C_lag0)], k = -horizon))))
#Need to get Recession Information because not included in Lags
REC_lagRESULT = window(zoo.C_lag0[,1], start = start(zoo.C_lagRESULT), end = end(zoo.C_lagRESULT))
train_start = start(zoo.C_lagRESULT)
train_end = end_train
test_start = as.Date(train_end) + months(h+1)
test_end = end(zoo.C_lagRESULT)
#Moving Window Size
#window = wind
#Setting Number of run (Not to be confused with M trees)
if(run.full == TRUE){
#run = (nrow(zoo.C_lagRESULT)-window-h - 1)
run = elapsed_months(test_end, test_start)
}
else{
run = runs
}
#Create prediction vector
pred_final = vector("numeric")
#cv_score = vector("integer")
#Create store for average and frequency count of variables selected
df.store = data.frame()
#Create positive prediction
pos_var = vector("integer")
pos_uniq = vector("integer")
#Time
ptm <- proc.time()
#Big for loop that will iterate about 400 times and predict out of sample and increment by 1
for(i in 1:run)
{
#Get zoo from 1 to 180, then 2 to 182, then 3 to 183 all the way to run + window so like 10 to 190
#shift  <- sum(i,window)
start_shift  <- months(i-1) + as.Date(train_start)
end_shift <- months(i-1) + as.Date(train_end)
zoo.C_shift =  window(zoo.C_lagRESULT, start = start_shift, end = end_shift)
REC_shift = window(REC_lagRESULT, start = start_shift, end = end_shift)
zoo.C_predict = window(zoo.C_lagRESULT, start = (as.Date(test_start)+months(i-1)), end = (as.Date(test_start)+months(i-1)))
#     gbm.C = gbm(REC_shift ~ . ,
#                 data = zoo.C_shift,
#                 distribution = distr,
#                 shrinkage = steps,
#                 bag.fraction = 1,
#                 cv.folds = 5,
#                 train.fraction = 1.0,
#                 n.trees = m)
#     gbm.C = gbm.fit(x = zoo.C_shift,
#                 y = REC_shift,
#                 distribution = distr,
#                 shrinkage = steps,
#                 bag.fraction = 1,
#                 n.trees = m,
#                 verbose = FALSE)
#
#Get the summary of GBM model
#     sum_gbm.C = summary(gbm.C, plotit= FALSE)
#Print best iteration and store
#best.iter_cv = gbm.perf(gbm.C, method="cv")
#cv_score[i] = best.iter_cv
cv_score = m
#Forecast using LAST time to forecast NEXT h period
#next_predict = sum(shift,h,1)
#     pred_final[i] =  predict(gbm.C,
#                             zoo.C_predict,
#                             n.trees= m,
#                             type="response")
pred_final[i] = 0
#Store number of positive variables
#     pos_var[i] = sum(as.numeric(sum_gbm.C[2] >0))
#Update average and frequency
#     if(length(df.store) == 0)
#     {
#       df.store = data.frame(NAME = sum_gbm.C[order(sum_gbm.C[[1]]),1], AVG = 0, FREQ = 0)
#       rownames(df.store) = df.store$NAME
#     }
#     if(length(df.store) > 0)
#     {
#       order_var = order(sum_gbm.C[[1]])
#       #Add I_j^2 value
#       df.store[,2] <- df.store[,2] + sum_gbm.C[order_var,2]
#       #Add to get frequency of each I_j^2
#       df.store[,3] <- df.store[,3] + as.numeric(sum_gbm.C[order_var,2]>0)
#     }
#
#
#
#     if(i %% 10 == 0)
#     {
#       cat(i)
#       save(pred_final, file = "~/Google Drive/Independent Work/Saved RData/save_pred_recent_gbm_roll.RData")
#       #save(pred_final, file = paste("gbm_",c,"_h",h,"d",d,"_pred_",run,"_.RData",sep=""))
#     }
}
#   #Print how long it took for ALL the run
#   time_spent = proc.time() - ptm
#
#   #Take average of I_j^2 value
#   df.store[,2] = df.store[,2]/run
#   df.store[,3] = df.store[,3]/run
#
#   #Return the average score from highest to lowest
#   df.store = df.store[order(df.store[,2], decreasing = TRUE),]
#
#   #Convert into time series object
ts.pred = ts(pred_final, start = c(year(test_start),month(test_start),day(test_start)), frequency = 12)
#ts.pos = ts(pos_var, start = c(year(test_start),month(test_start),day(test_start)), frequency = 12)
ts.REC = ts(REC_lagRESULT, start = c(year(test_start),month(test_start)), end = c(end(ts.pred)[1],end(ts.pred)[2]), frequency = 12)
#Plot Prediction Against ACTUAL Recession
plot(ts.REC, col = "blue", ylab = "Prob. of Recession", axes = FALSE)
par(new=TRUE)
plot(ts.pred, col = "red", ylab = "Prob. of Recession",
main = paste(c, ":", m, "Boosting Roll Forecast",h,"Months"),
axes = TRUE,
ylim=c(0,1))
#setwd("~/Google Drive/Independent Work/Writing/Graphs")
#dev.copy(png, paste(c,"_boost_","h",h,"d",d,"_outsample_",run,"_.png", sep = ""))
#dev.off()
#Return Prediction, Final Score, CV,Score and Ideally ROC
return(list(ts.REC,
ts.pred,
roc(ts.REC,ts.pred),
#df.store,
#ts.pos,
cv_score
#time_spent
))
}
gbm.US_h3d3_roll_mini = gbm.roc_roll(forecast = 3, lags = 3, zoo.US_lag0, run.full = FALSE, country = "US", runs = 10)
gbm.US_h3d3_roll_mini
gbm.US_h3d3_roll_mini = gbm.roc_roll(forecast = 3, lags = 3, zoo.US_lag0, run.full = TRUE, country = "US")
gbm.US_h3d3_roll_mini
gbm.US_h3d3_roll_mini[1]
end(gbm.US_h3d3_roll_mini[1])
(gbm.US_h3d3_roll_mini[1])
(gbm.US_h3d3_roll_mini[[1]])
end(gbm.US_h3d3_roll_mini[[1]])
gbm.roc_roll <- function(forecast = 0, lags = 3, zoo.C_lag0,  country, distr = "bernoulli", train = 1.0, run.full = TRUE, runs = 10,  m = 400, wind = 317, steps = 0.01, end_train = "1985-08-01")
{
h = forecast
d = lags
c = country
if(d == 0)
{
horizon = h + 1
}
else
{
horizon = seq(from =h+1, to = h+d)
}
#Lag h+1,h+2,...,h+d
zoo.C_lagRESULT = (na.omit(merge(lag(zoo.C_lag0[,2:ncol(zoo.C_lag0)], k = -horizon))))
#Need to get Recession Information because not included in Lags
REC_lagRESULT = window(zoo.C_lag0[,1], start = start(zoo.C_lagRESULT), end = end(zoo.C_lagRESULT))
train_start = start(zoo.C_lagRESULT)
train_end = end_train
test_start = as.Date(train_end) + months(h+1)
test_end = end(zoo.C_lagRESULT)
#Moving Window Size
#window = wind
#Setting Number of run (Not to be confused with M trees)
if(run.full == TRUE){
#run = (nrow(zoo.C_lagRESULT)-window-h - 1)
run = elapsed_months(test_end, test_start)
}
else{
run = runs
}
#Create prediction vector
pred_final = vector("numeric")
#cv_score = vector("integer")
#Create store for average and frequency count of variables selected
df.store = data.frame()
#Create positive prediction
pos_var = vector("integer")
pos_uniq = vector("integer")
#Time
ptm <- proc.time()
#Big for loop that will iterate about 400 times and predict out of sample and increment by 1
for(i in 1:sum(run,1))
{
#Get zoo from 1 to 180, then 2 to 182, then 3 to 183 all the way to run + window so like 10 to 190
#shift  <- sum(i,window)
start_shift  <- months(i-1) + as.Date(train_start)
end_shift <- months(i-1) + as.Date(train_end)
zoo.C_shift =  window(zoo.C_lagRESULT, start = start_shift, end = end_shift)
REC_shift = window(REC_lagRESULT, start = start_shift, end = end_shift)
zoo.C_predict = window(zoo.C_lagRESULT, start = (as.Date(test_start)+months(i-1)), end = (as.Date(test_start)+months(i-1)))
#     gbm.C = gbm(REC_shift ~ . ,
#                 data = zoo.C_shift,
#                 distribution = distr,
#                 shrinkage = steps,
#                 bag.fraction = 1,
#                 cv.folds = 5,
#                 train.fraction = 1.0,
#                 n.trees = m)
#     gbm.C = gbm.fit(x = zoo.C_shift,
#                 y = REC_shift,
#                 distribution = distr,
#                 shrinkage = steps,
#                 bag.fraction = 1,
#                 n.trees = m,
#                 verbose = FALSE)
#
#Get the summary of GBM model
#     sum_gbm.C = summary(gbm.C, plotit= FALSE)
#Print best iteration and store
#best.iter_cv = gbm.perf(gbm.C, method="cv")
#cv_score[i] = best.iter_cv
cv_score = m
#Forecast using LAST time to forecast NEXT h period
#next_predict = sum(shift,h,1)
#     pred_final[i] =  predict(gbm.C,
#                             zoo.C_predict,
#                             n.trees= m,
#                             type="response")
pred_final[i] = 0
#Store number of positive variables
#     pos_var[i] = sum(as.numeric(sum_gbm.C[2] >0))
#Update average and frequency
#     if(length(df.store) == 0)
#     {
#       df.store = data.frame(NAME = sum_gbm.C[order(sum_gbm.C[[1]]),1], AVG = 0, FREQ = 0)
#       rownames(df.store) = df.store$NAME
#     }
#     if(length(df.store) > 0)
#     {
#       order_var = order(sum_gbm.C[[1]])
#       #Add I_j^2 value
#       df.store[,2] <- df.store[,2] + sum_gbm.C[order_var,2]
#       #Add to get frequency of each I_j^2
#       df.store[,3] <- df.store[,3] + as.numeric(sum_gbm.C[order_var,2]>0)
#     }
#
#
#
#     if(i %% 10 == 0)
#     {
#       cat(i)
#       save(pred_final, file = "~/Google Drive/Independent Work/Saved RData/save_pred_recent_gbm_roll.RData")
#       #save(pred_final, file = paste("gbm_",c,"_h",h,"d",d,"_pred_",run,"_.RData",sep=""))
#     }
}
#   #Print how long it took for ALL the run
#   time_spent = proc.time() - ptm
#
#   #Take average of I_j^2 value
#   df.store[,2] = df.store[,2]/run
#   df.store[,3] = df.store[,3]/run
#
#   #Return the average score from highest to lowest
#   df.store = df.store[order(df.store[,2], decreasing = TRUE),]
#
#   #Convert into time series object
ts.pred = ts(pred_final, start = c(year(test_start),month(test_start),day(test_start)), frequency = 12)
#ts.pos = ts(pos_var, start = c(year(test_start),month(test_start),day(test_start)), frequency = 12)
ts.REC = ts(REC_lagRESULT, start = c(year(test_start),month(test_start)), end = c(end(ts.pred)[1],end(ts.pred)[2]), frequency = 12)
#Plot Prediction Against ACTUAL Recession
plot(ts.REC, col = "blue", ylab = "Prob. of Recession", axes = FALSE)
par(new=TRUE)
plot(ts.pred, col = "red", ylab = "Prob. of Recession",
main = paste(c, ":", m, "Boosting Roll Forecast",h,"Months"),
axes = TRUE,
ylim=c(0,1))
#setwd("~/Google Drive/Independent Work/Writing/Graphs")
#dev.copy(png, paste(c,"_boost_","h",h,"d",d,"_outsample_",run,"_.png", sep = ""))
#dev.off()
#Return Prediction, Final Score, CV,Score and Ideally ROC
return(list(ts.REC,
ts.pred,
roc(ts.REC,ts.pred),
#df.store,
#ts.pos,
cv_score
#time_spent
))
}
gbm.US_h3d3_roll_mini = gbm.roc_roll(forecast = 3, lags = 3, zoo.US_lag0, run.full = TRUE, country = "US")
gbm.US_h3d3_roll_mini
zoo.JP_lag0 = transform_season_JP()
TRANSFORM_COUNTRY
## Transform Japan Function ##
transform_season_JP <- function()
{
#### Read in Data for Japan ####
strs.JP <- readLines("~/Google Drive/Independent Work/Data/Japan/JAPAN_ALL_TRUNC.csv")
df.JP <- read.csv(text=strs.JP,             # read from an R object rather than a file
skip=10,                # skip the first line
stringsAsFactors=FALSE
)
df.JP_header <- read.csv(text=strs.JP,             # read from an R object rather than a file
nrows=10,                # skip the first line
stringsAsFactors=FALSE,
row.names = 1
)
###Convert to Zoo###
df.JP = date_COUNTRY(df.JP)
zoo.JP = zoo_COUNTRY(df.JP)
#zoo.JP = window(zoo.JP, start = "1978-01-01", end = end(zoo.JP))
#missmap(zoo.JP, main="Japan Data - Missings Map",  col=c("yellow", "black"), legend=TRUE)
#Approximate couple missing values
#Impute values using the mean
zoo.JP = na.approx(zoo.JP)
zoo.JP = na.aggregate(zoo.JP)
##Demean Trend
JP_DEMEAN = names(df.JP_header['DEMEAN',df.JP_header['DEMEAN',] == 1])
zoo.JP_predemean = zoo.JP
zoo.JP = DEMEAN_COUNTRY(zoo.JP, JP_DEMEAN)
#raw_pre1992 = window(zoo.JP$JPNVT0060, start = "1963-01-01", end = "1991-12-01")
#raw_pre1992_demean = raw_pre1992 - mean(raw_pre1992)
#raw_post1992 = window(zoo.JP$JPNVT0060, start = "1992-1-01")
#raw_post1992_demean = raw_post1992 - mean(raw_post1992)
### Seasonally Adjust ###
JP_NSA = names(df.JP_header['NSA',df.JP_header['NSA',] == 1])
zoo.JP = SA_COUNTRY(zoo.JP, JP_NSA)
sort(df.JP_header['DONE_TRANS',])
JP_var_names <- function(name)
{
return(names(df.JP_header['NEED_TRANS',df.JP_header['NEED_TRANS',] == name]))
}
same_JP = JP_var_names(name = "LEVEL")
level_1D_JP = JP_var_names(name = "LEVEL_1D")
log_1D_JP  = JP_var_names(name = "LOG_1D")
log_2D_JP = JP_var_names(name = "LOG_2D")
log_transform <-function(zoo.C, log_0D)
{
return(log(zoo.C[,log_0D]))
}
zoo.JP_lag0 = TRANSFORM_COUNTRY(zoo.JP, same_JP, level_1D_JP, log_1D_JP, log_2D_JP)
#Merge Tankan Dataset
zoo.JP_TAN = approx_tankan_JP()
zoo.JP_TAN = window(zoo.JP_TAN, start = start(zoo.JP_lag0), end = end(zoo.JP_lag0))
zoo.JP_lag0 = merge(zoo.JP_lag0, zoo.JP_TAN)
#Remove NA from original data. Should only remove row 1 because of log_1D
zoo.JP_lag0 = na.omit(zoo.JP_lag0)
#missmap(zoo.JP_lag0, main="Japan Data - Missings Map",  col=c("yellow", "black"), legend=TRUE)
#Compare Original and Transformed
ncol(zoo.JP_lag0) #Have duplicates, also check for NaN
nrow(zoo.JP_lag0)
ncol(zoo.JP)
nrow(zoo.JP)
### Summary of Data ###
#Japan
autoplot.zoo(zoo.JP_lag0$JAPRECD, xlab = "Year", ylab = "Recession", col = "Red", main = "US Recessions 1978-2014")
#Look at Interest Rate Spread versus recession
autoplot.zoo(zoo.JP_lag0$INTSPREAD)
return(zoo.JP_lag0)
}
zoo.JP_lag0 = transform_season_JP()
zoo.JP_lag0
gbm.JP_h3d3_roll_full = gbm.roc_roll(forecast = 3, lags = 3, zoo.JP_lag0, run.full = TRUE, country = "JP", m = 400)
gbm.JP_h3d3_roll_full
gbm.JP_h3d3_roll_full = gbm.roc_roll(forecast = 3, lags = 3, zoo.JP_lag0, run.full = TRUE, country = "JP", m = 400, end_train = "1995-08-01")
gbm.JP_h3d3_roll_full
